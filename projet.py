import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.cluster.hierarchy import linkage, dendrogram
import math
import pandas as pd

points =[(1,1),(1,2),(1,5),(3,4),(4,3),(6,2),(0,4)]
noms= ["M1", "M2", "M3", "M4", "M5", "M6", "M7"]

#########################################
#               Partie 1                #
#########################################

print("\nPARTIE 1\n")

#S√©parer les coordonn√©es x et y
x = np.array([p[0] for p in points])
y = np.array([p[1] for p in points])


def afficher_stats(valeurs, noms):
    print("Moyenne :", np.mean(valeurs))
    print("M√©diane :", np.median(valeurs))
    print("Variance :", np.var(valeurs))
    print("Ecart-type :", np.std(valeurs))
    print("Minimum :", np.min(valeurs))
    print("Maximum :", np.max(valeurs))
    print("Etendue :", np.ptp(valeurs))


afficher_stats(x, "x")
afficher_stats(y, "y")

plt.scatter(x, y, color='blue')
for i in range(len(points)):
    plt.text(x[i] + 0.1, y[i] + 0.1, noms[i])
plt.title("Nuage de points")
plt.xlabel("x")
plt.ylabel("y")
plt.grid()
plt.show()

#   Interpr√©tation statistique :

#Les valeurs xx sont plus dispers√©es que les valeurs yy.
#La moyenne de xx est plus faible que celle de yy, indiquant une asym√©trie spatiale.
#L‚Äô√©tendue plus grande pour xx traduit une plus grande variabilit√© sur l‚Äôaxe horizontal.

#   Interpr√©tation graphique :

#Le nuage montre une certaine tendance croissante mais non strictement lin√©aire.
#Il est possible qu‚Äôune relation lin√©aire approximative existe entre xx et yy, √† tester dans la partie suivante.


#########################################
#               Partie 2                #
#########################################

print("\nPARTIE 2\n")

# 2.1 Calcul des Coefficients de R√©gression

# Moyennes
x_moy = np.mean(x)
y_moy = np.mean(y)

# Coefficients
b1 = np.sum((x - x_moy) * (y - y_moy)) / np.sum((x - x_moy)**2)
b0 = y_moy - b1 * x_moy

print("bo =", b0)
print("b1 =", b1)

# Mod√®le de pr√©dictions
y_pred = b0 + b1 * x


# 2.3 Coefficient de D√©termination R¬≤

# R¬≤
SCE = np.sum((y - y_pred) ** 2)
SCT = np.sum((y - y_moy) ** 2)
SCR = np.sum((y_pred - y_moy) ** 2)
R2 = 1 - SCE / SCT
print("R¬≤ (Coefficient de d√©termination) :", R2)


# 2.2 Visualisation de la Droite de R√©gression

# Affichage
plt.scatter(x, y, label='Points')
plt.plot(x, y_pred, color='red', label=f'Droite de r√©gression: y = {b0:.2f} + {b1:.2f}x')
plt.legend()
plt.title(f'Droite de r√©gression lin√©aire simple (R¬≤ = {R2:.2f})')
plt.xlabel("x")
plt.ylabel("y")
plt.grid(True)
plt.show()
plt.savefig("figure_2_1.jpg")
print("Graphique enregistr√© dans le fichier figure_2_1.jpg")


#########################################
#               Partie 3                #
#########################################

print("\nPARTIE 3\n")

#1. R√©sidus et somme des carr√©s des erreurs (SCE)
e = y - y_pred

SCE=0

for i in range(len(points)):
    SCE += e[i]**2 
print("SCE (Somme des carr√©s des erreurs) :", SCE)

#2. Etimation de la variance des erreurs : MSE
n= len(x)

MSE = SCE / (n-2)

print("MSE (Erreur quadratique moyenne) :", MSE)

#Le n-2 vient du fait qu'on a estim√© 2 param√®tres (b0 et b1). On parle alors de degr√©s de libert√©.

#3. Ecart-type des erreurs
s = np.sqrt(MSE)

print("√âcart-type des erreurs :", s)

#4. Interpr√©tation des R√©sultats

# üîπ Interpr√©tation des coefficients

#     b0=3.33 (ordonn√©e √† l'origine) : c'est la valeur estim√©e de y quand x=0. Cela signifie qu'√† l'origine de l'axe x, la droite de r√©gression pr√©voit y=3.33.

#     b1=‚àí0.15 (pente) : chaque augmentation de 1 unit√© en x entra√Æne une baisse moyenne de y de 0.15. La relation est donc l√©g√®rement d√©croissante, mais tr√®s faible.

# üîπ Coefficient de d√©termination R2

#     Le R2=0.049 (soit 4.9%) indique que seulement 4.9% de la variation de y est expliqu√©e par la variable x.

#     Cela signifie que la droite de r√©gression explique tr√®s peu la variabilit√© des points. La majorit√© de la variation de y provient donc d'autres facteurs non captur√©s par ce mod√®le.

# üîπ Analyse des erreurs

#     SCE (Somme des carr√©s des erreurs) : 11.42
#     ‚Üí mesure l‚Äôerreur globale du mod√®le (plus elle est faible, meilleur est l‚Äôajustement).

#     MSE (Erreur quadratique moyenne) : 2.28
#     ‚Üí estimation de la variance des erreurs r√©siduelles.

#     √âcart-type des erreurs : 1.51
#     ‚Üí en moyenne, les pr√©dictions du mod√®le s‚Äô√©cartent de 1.51 unit√©s des valeurs r√©elles.

#     Compar√© √† l‚Äô√©cart-type total de y qui est de 1.31, cela montre que la droite n'am√©liore pas vraiment la pr√©diction par rapport √† une moyenne constante.

#########################################
#               Partie 4                #
#########################################

print("\nPARTIE 4\n")

# 4.1 Estimation de la variance des erreurs

# 4.2 Erreurs Standards des Coefficients

# Erreur standard de la pente
somme_x=0
for i in range(len(points)):
    somme_x += (x[i]-x_moy)**2

SEb1 = s/np.sqrt(somme_x)
print("Erreur standard de la pente (SEb1):", SEb1)

# Erreur standard de l'ordonn√©e √† l'origine
SEb0 = s*np.sqrt(1/n+x_moy**2/somme_x)
print("Erreur standard de l'ordonn√©e √† l'origine (SEb0)", SEb0)
print("\n")

# 4.3 Test d'Hypoth√®se pour la Pente (b1)

# Hypoth√®ses :
# H0 : b1 = 0 (pas de relation lin√©aire)
# H1 : b1 != 0 (relation lin√©aire significative)

# Statistique de test

t_b1 = (b1-0)/SEb1 # t suit une loi de Student donc on calcul la p-valeur pour savoir si on rejette l'hypoth√®se ou non
p_b1 = 2 * (1 - stats.t.cdf(abs(t_b1), df=n - 2))
print("b1 :")
print("valeur de test", t_b1)
print("p-valeur:", p_b1)
if(p_b1<0.05):
    print("p-valeur<0,05 donc on rejette l'hypoth√®se, b1 est significatif")
else:
    print("p-valeur>0,05 donc on ne rejette pas l'hypoth√®se, il n'y a pas de preuve de relation lin√©aire")
print("b1 = ", b1)
print("\n")

# 4.4 Test d'Hypoth√®se pour l'Ordonn√©e √† l'Origine (b0)
# Hypoth√®ses : H0 : b0 = 0 vs H1 : b0 != 0

# Statistique de test

t_b0 = (b0-0)/SEb0
p_b0 = 2 * (1 - stats.t.cdf(abs(t_b0), df=n - 2))
print("b0 :")
print("valeur de test", t_b0)
print("p-valeur:", p_b0)
if(p_b0<0.05):
    print("p-valeur<0,05 donc on rejette l'hypoth√®se, b0 est significatif, la constante n'est pas nulle")
else:
    print("p-valeur>0,05 donc on ne rejette pas l'hypoth√®se, il n'y a pas de preuve de relation lin√©aire, b0 n'est pas significatif")
print("b0 = ", b0)
print("\n")

# 4.5 Intervalles de Confiance pour les Coefficients

alpha = 0.05

t_crit = stats.t.ppf(1-alpha/2, df= n-2)

IC_b1=[float(b1-t_crit*SEb1),float(b1+t_crit*SEb1)]
IC_b0=[float(b0-t_crit*SEb0),float(b0+t_crit*SEb0)]

print("Intervalle de confiance √† 95% pour b1:", IC_b1)
print("Intervalle de confiance √† 95% pour b0:", IC_b0)

# 4.6 Interpr√©tation des Tests Statistiques

# Pour l'erreur standard des coefficients on a :
#   Erreur standard de la pente SEb1 = 0.2885
#   Erreur standard √† l'ordonn√©e √† l'origine SEb0 = 0.8724

# Test d'hypoth√®se pour la pente (b1) :
#   Hypoth√®ses :
#        H0 : b1 = 0 (pas de relation lin√©aire)
#        H1 : b1 != 0 (relation lin√©aire significative)
#   Statistique de test t : -0.5054
#   p-valeur : 0.6347 (> 0.05)
#   Conclusion :
#       On ne rejette pas H0.
#       Il n‚Äôy a pas de preuve statistique d‚Äôune relation lin√©aire significative entre les variables.
#       Autrement dit, la pente n‚Äôest pas significative.

# Test d'hypoth√®se pour l'ordonn√©e √† l'origine (b0) :
#   Hypoth√®ses :
#        H0 : b0 = 0 (la constante est nulle)
#        H1 : b0 != 0 (la constante est significativement diff√©rente de 0)
#   Statistique de test t : 3.8208
#   p-valeur : 0.0124 (< 0.05)
#   Conclusion :
#       On rejette H0.
#       La constante est significativement diff√©rente de 0.

# Intervalle de confiance √† 95% :
#   Pour b1 (la pente):
#       [-0.8875, 0.5958]
#       Contient z√©ro donc coh√©rent avec le fait que b1 n‚Äôest pas significatif.
#   Pour b0 (l'ordonn√©e √† l'origine) :
#       [1.0907, 5.5760]
#       Ne contient pas z√©ro donc confirme que b0 est significatif.

# Interpr√©tation finale : 
#   La constante b0 est significative : le mod√®le pr√©dit une valeur moyenne de y autour de 3.33 m√™me quand x = 0.
#   La pente b1 n‚Äôest pas significative : la variable explicative x n‚Äôexplique pas de mani√®re significative la variation de y dans notre √©chantillon.
#   On pourrait envisager d'autres mod√®les, transformations de variables, ou d‚Äôaugmenter la taille de l‚Äô√©chantillon si on soup√ßonne une relation qui n‚Äôappara√Æt pas ici.

#########################################
#               Partie 5                #
#########################################

print("\nPARTIE 5\n")

# Classification Ascendante Hi√©rarchique (CAH)

# 1.a
def dist(p1, p2):
    '''
    Cette fonction prend deux couples de points en param√®tre et retourne une distance entre ces deux points
    :param p1 : premier couple de point
    :param p2 : second couple de point
    :return : la distance entre ces deux points
    '''
    """Distance euclidienne"""
    distance = math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)
    print("La distance euclidienne vaut : ", distance)
    return distance

# 1.b
def dist1(p1, p2):
    '''
    Cette fonction prend deux couples de points en param√®tre et retourne une distance entre ces deux points
    :param p1 : premier couple de point
    :param p2 : second couple de point
    :return : la distance entre ces deux points
    '''
    """Distance de Manhattan"""
    distance = abs(p1[0]-p2[0]) + abs(p1[1]-p2[1])
    print("La distance de Manhattan vaut : ", distance)
    return distance

# 1.c
def dist_inf(p1, p2):
    '''
    Cette fonction prend deux couples de points en param√®tre et retourne une distance entre ces deux points
    :param p1 : premier couple de point
    :param p2 : second couple de point
    :return : la distance entre ces deux points
    '''
    """Distance de Chebyshev (max)"""
    distance = max(abs(p1[0]-p2[0]), abs(p1[1]-p2[1]))
    print("La distance de Chebyshev vaut : ", distance)
    return distance

# 1.d : Distance de Ward ???


# 2.
def dist_min(tableau, dist_func):
    '''
    Cette fonction prend un tableau et une fonction en param√®tre et retourne un couple de point situ√©s √† une distance minimale l'un de l'autre
    :param : tableau : un tableau de points
    :param : dist_func : la fonction du calcul de la distance entre deux points que l'on veut utiliser
    :return : un couple de points
    '''
    min_d = float('inf')
    couple_points = None
    for i in range(len(tableau)):
        for j in range(i+1, len(tableau)):                  #Permet de parcourir toutes les lignes et toutes les colonnes d'un tableau 
            d = dist_func(tableau[i], tableau[j])           #R√©cup√®re la distance √† partir de la fonction donn√©e en entr√©e
            if d < min_d:                                   #Calcul de toutes les distances entre les points et garde la distance minimum
                min_d = d
                couple_points = (tableau[i], tableau[j])
    return couple_points, min_d


# 3.

# Initialisation de la matrice
n = len(x)
matrice_1 = np.zeros((n, n))

# Remplissage de la matrice avec d¬≤
for i in range(n):
    for j in range(n):
        xi, yi = points[i]
        xj, yj = points[j]
        d_eucli = dist(points[i], points[j])
        d_eucli_2 = d_eucli**2
        matrice_1[i][j] = d_eucli_2

# Affichage avec pandas pour lisibilit√©
data = pd.DataFrame(matrice_1, index=y, columns=x)
print("Matrice des distances euclidiennes au carr√© :\n")
print(data.round(1))

# Trac√©
plt.scatter(x, y, color='blue')
for i in range(len(points)):
    plt.text(x[i] + 0.1, y[i] + 0.1, noms[i])
plt.title("Nuage de points")
plt.xlabel("x")
plt.ylabel("y")

pair_min, d_min = dist_min(points, dist)

print("La paire de points les plus proche est : ", pair_min)

x_vals = [pair_min[0][0], pair_min[0][1]]
y_vals = [pair_min[1][0], pair_min[1][1]]

#x_vals, y_vals = dist_min(matrice_1, dist)

# Encadrer les 2 points les plus proches (Classe Œì‚ÇÅ)
plt.plot(x_vals, y_vals, 'go--', label="Classe Œì1")
plt.scatter(x_vals, y_vals, color='green')
plt.title("Regroupement en classes")
plt.grid(True)
plt.xlim(-1, 7)
plt.ylim(0, 6)

# plt.savefig("figure_5_3.jpg")
# print("Graphique enregistr√© dans le fichier figure_5_3.jpg")


#4.
# Points de Gamma1 (groupe initial)
# dist_min retourne un couple de points (p1, p2)
p1, p2 = pair_min

# retrouver les indices de ces points dans la liste points
i = points.index(p1)
j = points.index(p2)

Gamma1 = [points[i], points[j]]
Gamma1_nom = "G1"

# Points restants
reste_points = []
reste_noms = []
for k in range(n):
    if k != i and k != j:
        reste_points.append(points[k])
        reste_noms.append(noms[k])

# Fonction : distance entre un point et un segment [A,B]
'''calcule la distance au carr√© entre un point P(px, py) et
un segment d√©fini par les points A(ax, ay) et B(bx, by)'''
def distance_point_segment(px, py, ax, ay, bx, by):
    #Composantes du vecteur AB
    ABx = bx - ax
    ABy = by - ay

    #Composantes du vecteur AP
    APx = px - ax
    APy = py - ay

    #Carr√© de la longueur du segment AB
    ab2 = ABx**2 + ABy**2
    if ab2 == 0: #si A et B sont confondus, alors c'est une distance avec un point
        return (px - ax)**2 + (py - ay)**2
    
    #Projection orthogonale
    t = (APx * ABx + APy * ABy) / ab2
    if t < 0: #la projection est avant A donc A est le plus proche
        closest_x, closest_y = ax, ay
    elif t > 1: #la projection est apr√®s B donc B est le plus proche
        closest_x, closest_y = bx, by
    else:
        closest_x = ax + t * ABx
        closest_y = ay + t * ABy

    #On retourne la distance au carr√© entre P et le point le plus proche du segment AB
    dx = px - closest_x
    dy = py - closest_y

    return dx**2 +dy**2

# Matrice 6x6 : Gamma1 + 5 autres points
noms_total = [Gamma1_nom] + reste_noms
taille = len(noms_total)
matrice_2 = np.zeros((taille, taille))

for a in range(taille):
    for b in range(taille):
        if a == b: #la matrice est nulle sur la diagonale
            matrice_2[a][b] = 0
        elif a == 0: #distance entre le point et Gamma 1 (distance segment-point)
            px, py = reste_points[b - 1]
            ax, ay = Gamma1[0]
            bx, by = Gamma1[1]
            matrice_2[a][b] = distance_point_segment(px, py, ax, ay, bx, by)
        elif b == 0: #distance entre Gamma 1 et le point (distance segment-point)
            px, py = reste_points[a - 1]
            ax, ay = Gamma1[0]
            bx, by = Gamma1[1]
            matrice_2[a][b] = distance_point_segment(px, py, ax, ay, bx, by)
        else: #distance entre deux points
            matrice_2[a][b] = dist(reste_points[a - 1],reste_points[b - 1])

# Affichage final
print("Matrice avec Gamma1 et les autres points (distances au carr√©) \n")
df = pd.DataFrame(matrice_2, index=noms_total, columns=noms_total)
print(df.round(1))

#Trouver Gamma2

'''trouver la distance minimale dans une matrice, ainsi que les points correspondants
sauf sur la diagonale'''
def trouver_distance_minimale(matrice, noms):
    min_dist = float('inf')
    indices = (-1, -1)
    
    for i in range(len(matrice)):
        for j in range(len(matrice)):
            if i != j and matrice[i][j] < min_dist:
                min_dist = matrice[i][j]
                indices = (i, j)
    
    nom_i = noms[indices[0]]
    nom_j = noms[indices[1]]
    return nom_i, nom_j, min_dist


p1_min, p2_min, d_min = trouver_distance_minimale(matrice_2, noms_total)

# retrouver les indices de ces points dans la liste points
i = noms_total.index(p1_min)
j = noms_total.index(p2_min)

# p1_min et p2_min sont des noms
Gamma2_noms = [p1_min, p2_min]
Gamma2 = []           # les points de Gamma2
reste_points2 = []    # les autres points
reste_noms2 = []      # leurs noms

# On boucle sur noms et points restants (sauf G1 d√©j√† group√©)
for i in range(1, len(noms_total)):  # on saute "G1", qui est d√©j√† dans Gamma1
    nom = noms_total[i]
    pt = reste_points[i - 1]  # car reste_points n'inclut pas "G1"
    
    if nom in Gamma2_noms:
        Gamma2.append(pt)
    else:
        reste_points2.append(pt)
        reste_noms2.append(nom)

# Construction de la matrice 3 (G1, G2, autres points restants)
groupes = [Gamma1, Gamma2]  # listes de 2 points chacun
noms_total2 = ["G1", "G2"] + reste_noms2
tous_points = groupes + [[p] for p in reste_points2]  # chaque point devient un "groupe d‚Äôun point"
taille = len(tous_points)

matrice_3 = np.zeros((taille, taille))

for i in range(taille):
    for j in range(taille):
        if i == j: #sur la diagonale
            matrice_3[i][j] = 0
        else:
            # Si un des deux est un groupe (contient 2 points), on fait la distance segment-point
            if len(tous_points[i]) == 2 and len(tous_points[j]) == 1:
                px, py = tous_points[j][0]

                #i est le segment
                ax, ay = tous_points[i][0]
                bx, by = tous_points[i][1]

                matrice_3[i][j] = distance_point_segment(px, py, ax, ay, bx, by)
            elif len(tous_points[i]) == 1 and len(tous_points[j]) == 2:
                px, py = tous_points[i][0]

                #j est le segment
                ax, ay = tous_points[j][0]
                bx, by = tous_points[j][1]

                matrice_3[i][j] = distance_point_segment(px, py, ax, ay, bx, by)
            else:
                # distance entre deux points
                x1, y1 = tous_points[i][0]
                x2, y2 = tous_points[j][0]
                matrice_3[i][j] = (x1 - x2)**2 + (y1 - y2)**2

            matrice_2[a][b] = (x1 - x2)**2 + (y1 - y2)**2

# Affichage final
print("Matrice avec Gamma2 et les autres points (distances au carr√©) \n")
df = pd.DataFrame(matrice_3, index=noms_total2, columns=noms_total2)
print(df.round(1))

#Trac√©

'''r√©cup√®re les coordonn√©es des points sachant qu'on connait leurs noms'''
def coord_from_nom(nom, groupes_dict):
    if nom in groupes_dict:
        return groupes_dict[nom][0]
    else:
        return points[noms.index(nom)]

groupes_dict = {"G1": Gamma1, "G2": Gamma2}

x1, y1 = coord_from_nom(p1_min, groupes_dict)
x2, y2 = coord_from_nom(p2_min, groupes_dict)

x_vals2 = [x1, x2]
y_vals2 = [y1, y2]

plt.plot(x_vals2, y_vals2, 'ro--', label="Classe Œì2")
plt.scatter(x_vals2, y_vals2, color='red')


#5.

# Trouver Gamma3 (deux √©l√©ments les plus proches)
p3_min, p4_min, d_min3 = trouver_distance_minimale(matrice_3, noms_total2)

Gamma3_noms = [p3_min, p4_min]
Gamma3 = []

reste_points3 = []
reste_noms3 = []

for i in range(len(noms_total2)):
    nom = noms_total2[i]
    pt = tous_points[i]  # soit un groupe, soit un point (encapsul√© dans une liste)

    if nom in Gamma3_noms:
        Gamma3 += pt  # ajoute les points au nouveau groupe
    else:
        reste_points3.append(pt)
        reste_noms3.append(nom)

noms_total3 = ["G3"] + reste_noms3
tous_points3 = [Gamma3] + reste_points3

taille4 = len(tous_points3)
matrice_4 = np.zeros((taille4, taille4))

for i in range(taille4):
    for j in range(taille4):
        if i == j:
            matrice_4[i][j] = 0
        else:
             # Si un des deux est un groupe (contient 2 points), on fait la distance segment-point
            if len(tous_points3[i]) == 2 and len(tous_points3[j]) == 1:
                px, py = tous_points3[j][0]

                #i est le segment
                ax, ay = tous_points3[i][0]
                bx, by = tous_points3[i][1]

                matrice_4[i][j] = distance_point_segment(px, py, ax, ay, bx, by)

            elif len(tous_points3[i]) == 1 and len(tous_points3[j]) == 2:
                px, py = tous_points3[i][0]

                #j est le segment
                ax, ay = tous_points3[j][0]
                bx, by = tous_points3[j][1]
                matrice_4[i][j] = distance_point_segment(px, py, ax, ay, bx, by)
            else:
                #distance entre deux points
                x1, y1 = tous_points3[i][0]
                x2, y2 = tous_points3[j][0]

                matrice_4[i][j] = (x1 - x2)**2 + (y1 - y2)**2


df = pd.DataFrame(matrice_4, index=noms_total3, columns=noms_total3)
print("Matrice avec Gamma3 et les autres points :\n")
print(df.round(1))

groupes_dict = {"G1": Gamma1, "G2": Gamma2, "G3": Gamma3}

x1, y1 = coord_from_nom(p3_min, groupes_dict)
x2, y2 = coord_from_nom(p4_min, groupes_dict)

x_vals3 = [x1, x2]
y_vals3 = [y1, y2]

plt.plot(x_vals3, y_vals3, 'o--', color='orange', label="Classe Œì3")
plt.scatter(x_vals3, y_vals3, color='orange')
plt.show()

# 6.

# √âtape 1 : calcul de la matrice de linkage avec m√©thode "single"
# La fonction linkage construit la hi√©rarchie de regroupement en utilisant la distance euclidienne.
# Ici, on utilise la m√©thode 'single' (plus proche voisin), ce qui signifie que la distance entre deux groupes est d√©finie comme la distance minimale entre un point de l'un et un point de l'autre.
# Cette ligne automatise toutes les √©tapes de fusion des groupes jusqu'√† ce qu'il n'en reste plus qu'un.
linked = linkage(points, method='single', metric='euclidean') # La variable linked contient toutes les √©tapes de regroupement.

# √âtape 2 : Affichage du dendrogramme
# La fonction dendrogram() affiche visuellement les fusions successives entre groupes.
# Chaque branche repr√©sente une √©tape de regroupement ; plus elle est haute, plus la distance entre les groupes fusionn√©s est grande.
# Les labels permettent de visualiser quels points (M1 √† M7) sont fusionn√©s √† chaque √©tape.
# Cela remplace et r√©sume graphiquement toutes les √©tapes manuelles de la classification (Œì1, Œì2, etc.).
plt.figure(figsize=(10, 6))
dendrogram(linked, labels=["M1", "M2", "M3", "M4", "M5", "M6", "M7"])
plt.title('Dendrogramme - CAH (single linkage)')
plt.xlabel('Points')
plt.ylabel('Distance euclidienne')
plt.grid(True)
plt.show()
